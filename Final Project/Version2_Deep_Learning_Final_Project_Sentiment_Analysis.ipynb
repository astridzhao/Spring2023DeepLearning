{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstridZhao/Spring2023DeepLearning/blob/main/Version2_Deep_Learning_Final_Project_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFog3lU7Mzws"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow transformers datasets\n",
        "!pip install pytreebank\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1EyPhee2Qhh"
      },
      "source": [
        "# Sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YQ3fHHF2Vb2"
      },
      "outputs": [],
      "source": [
        "import pytreebank\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import time\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALmXs4XR2lFX"
      },
      "source": [
        "# Data acquisition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auvfOWmAQN1U"
      },
      "source": [
        "Import dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPrHceyRPJrq"
      },
      "outputs": [],
      "source": [
        "# Load the dataset from disk\n",
        "dataset = pytreebank.load_sst(\"/path/to/sentiment/\")\n",
        "\n",
        "train = dataset['train']\n",
        "validation = dataset['dev']\n",
        "test = dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffJNoUv0VP3t"
      },
      "source": [
        "Due to the costs of running ChatGPT queries, we limit the number of training and test samples. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LaP_azOVY2d"
      },
      "outputs": [],
      "source": [
        "limit = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlTKIrifFJcW"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "train_data = []\n",
        "for tree in train:\n",
        "  datapoint = tree.to_labeled_lines()[0]\n",
        "  train_data.append(datapoint)\n",
        "  \n",
        "train_data = train_data[:limit]\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  for label, sentence in train_data:\n",
        "    X_train.append(sentence)\n",
        "    Y_train.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaHPTCOLD1cX"
      },
      "outputs": [],
      "source": [
        "X_valid = []\n",
        "Y_valid = []\n",
        "\n",
        "valid_data = []\n",
        "for tree in validation:\n",
        "  datapoint = tree.to_labeled_lines()[0]\n",
        "  valid_data.append(datapoint)\n",
        "\n",
        "valid_data = valid_data[:limit]\n",
        "\n",
        "for i in range(len(valid_data)):\n",
        "  for label, sentence in valid_data:\n",
        "    X_valid.append(sentence)\n",
        "    Y_valid.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STH3FyZuEVut"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "test_data = []\n",
        "for tree in test:\n",
        "  datapoint = tree.to_labeled_lines()[0]\n",
        "  test_data.append(datapoint)\n",
        "\n",
        "test_data = test_data[:limit]\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  for label, sentence in test_data:\n",
        "    X_test.append(sentence)\n",
        "    Y_test.append(label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBwlTsQh6O0y"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL3tgnIj6OaQ"
      },
      "outputs": [],
      "source": [
        "def create_prompt(sentence, label, prediction=False):\n",
        "    result = \"\"\n",
        "    if label == 0 : sentiment = \"very negative\" \n",
        "    elif label == 1: sentiment = \"negative\"\n",
        "    elif label == 2: sentiment = \"neutral\" \n",
        "    elif label == 3: sentiment = \"positive\" \n",
        "    elif label == 4: sentiment = \"very positive\" \n",
        "\n",
        "    result    = f\"Sentiment analysis, input text: [{sentence}]\\nSentiment: [\"\n",
        "    if prediction==False:\n",
        "      result  += f\"{sentiment}]\\n\"\n",
        "    return result\n",
        "\n",
        "formatted_prompts_train = [create_prompt(sentence, sentiment) for sentence, sentiment in list(zip(X_train, Y_train))]\n",
        "formatted_prompts_test  = [create_prompt(sentence, sentiment) for sentence, sentiment in list(zip(X_test, Y_test))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrfjsgbc_BNa",
        "outputId": "08650d36-d1a9-4635-d8df-0255be56cd15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sentiment analysis, input text: [Effective but too-tepid biopic]\\nSentiment: [neutral]\\n',\n",
              " 'Sentiment analysis, input text: [If you sometimes like to go to the movies to have fun , Wasabi is a good place to start .]\\nSentiment: [positive]\\n',\n",
              " \"Sentiment analysis, input text: [Emerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one .]\\nSentiment: [very positive]\\n\",\n",
              " 'Sentiment analysis, input text: [The film provides some great insight into the neurotic mindset of all comics -- even those who have reached the absolute top of the game .]\\nSentiment: [neutral]\\n',\n",
              " 'Sentiment analysis, input text: [Offers that rare combination of entertainment and education .]\\nSentiment: [very positive]\\n',\n",
              " 'Sentiment analysis, input text: [Perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions .]\\nSentiment: [positive]\\n',\n",
              " \"Sentiment analysis, input text: [Steers turns in a snappy screenplay that curls at the edges ; it 's so clever you want to hate it .]\\nSentiment: [positive]\\n\",\n",
              " 'Sentiment analysis, input text: [But he somehow pulls it off .]\\nSentiment: [positive]\\n',\n",
              " 'Sentiment analysis, input text: [Take Care of My Cat offers a refreshingly different slice of Asian cinema .]\\nSentiment: [positive]\\n',\n",
              " 'Sentiment analysis, input text: [This is a film well worth seeing , talking and singing heads and all .]\\nSentiment: [very positive]\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "formatted_prompts_test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRu1hadc19tU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets openai\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\" # keep it safe\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\", max_tokens=500, temperature=0.0, n=1):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    if model==\"gpt-3.5-turbo\":\n",
        "      response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        n=n)\n",
        "      result = response.choices[0].message[\"content\"]\n",
        "    else:\n",
        "      response = openai.Completion.create(\n",
        "        model=model,\n",
        "        prompt=prompt,\n",
        "        max_tokens=max_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=n          \n",
        "      )\n",
        "      result = response.choices[0].text\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FAzenrAQY_b"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRFlv1O7Q8mN"
      },
      "outputs": [],
      "source": [
        "def evaluate(Y_true,Y_preds):\n",
        "  print(classification_report(Y_true,Y_preds))\n",
        "  conf = confusion_matrix(Y_true,Y_preds)\n",
        "  sns.heatmap(conf, fmt='d', annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mfsFtGUVq4n"
      },
      "source": [
        "We choose to use Few-shot learning method. \n",
        "It is to give a longer prompt and training examples as a prompt for a chat model, and then we could predict the sentiment of the test sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHOrMWgLI78M"
      },
      "outputs": [],
      "source": [
        "instructions = \"\\n\".join(formatted_prompts_train[:80])\n",
        "prompt = \"You are a movie review expert and identifying the sentiment of review. \"\\\n",
        "         \" I will define the input text of review sentence in the first bracket[], and then the sentiment is in the second bracket[] between\\n and \\n tags.\"\\\n",
        "        \"Be as precise, as you can. Identify the sentiment of the input text defined in brackets, \" \\\n",
        "          \"and return the sentiment in brackets too. The return value should be positive or negative, \" \\\n",
        "          \" nothing else. Here are some examples, how to do it:\\n\"\n",
        "# prompt =  \"You are a movie review expert and identifying the sentiment of review. \"\\\n",
        "#           \"Identifying the sentiment of the input text defined in brackets, \" \\\n",
        "#           \"and returning the sentiment result in brackets too. The return value should be\" \\\n",
        "#           \"ONLY the words of one of five words following: \" \\\n",
        "#           \"positive, very positive, neutral, very negative, negative.\"\\\n",
        "#           \"Here are some examples, how to do it:\\n\"\n",
        "\n",
        "# \" Your job is returning the sentiment result in the brackets. \" \\\n",
        "# \" The return value should be ONLY the words of one of five words in the following curly brackets: {positive, very positive, neutral, very negative, negative}\" \\\n",
        "          \n",
        "prompt += instructions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXGfkCZRb7-b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "32b82e7b-cd29-4a62-8952-2b48b1b5996d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sentiment analysis, input text: [The acting in this movie was terrible and the plot was completely nonsensical.]\\nSentiment: [negative]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "prompt += formatted_prompts_train[0]\n",
        "get_completion(prompt , model=\"gpt-3.5-turbo\") # initialize a chatgpt model with the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jE07u_9July"
      },
      "outputs": [],
      "source": [
        "preds_text2 = []\n",
        "counter=0 # to be able to continue, if the connection breaks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,80):\n",
        "   result = ''\n",
        "   prompt = \"You are a movie review expert and identifying the sentiment of review. \"\\\n",
        "         \" I will define the input text of review sentence in the first bracket[], and then the sentiment is in the second bracket[] between\\n and \\n tags.\"\\\n",
        "        \"Be as precise, as you can. Identify the sentiment of the input text defined in brackets, \" \\\n",
        "          \"and return the sentiment in brackets too. The return value should be positive or negative, \" \\\n",
        "          \" nothing else. Here are some examples, how to do it:\\n\"\n",
        "   prompt += formatted_prompts_test[i]\n",
        "   result = get_completion(prompt, model=\"gpt-3.5-turbo\")\n",
        "   preds_text2.append(result)\n",
        "   "
      ],
      "metadata": {
        "id": "x33wQN5PTVoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGZ1poMQLyu-"
      },
      "outputs": [],
      "source": [
        "def convert_text_to_label(text):\n",
        "  pos = ['positive','very positive','happy','nostalgic','Amazing','Fantastic', 'Excellent', 'Great', 'Outstanding', 'Brilliant', 'Superb', 'Terrific', 'Impressive', 'Delightful']\n",
        "  neg = ['negative','very negative','frustration','sad','concerned','embarrassment','Horrible', 'Disappointing', 'Bad', 'Mediocre', 'Dreadful', 'Abysmal', 'Atrocious', 'Lousy']\n",
        "  net = ['neutral','mixed','Okay', 'Average', 'Decent', 'Fair', 'Ordinary', 'Fine', 'Acceptable', 'Satisfactory', 'Balanced', 'Unremarkable']\n",
        "  if any([x in text.lower() for x in pos]): \n",
        "    return 1\n",
        "  elif any([x in text.lower() for x in neg]): \n",
        "    return -1\n",
        "  elif any([x in text.lower() for x in net]): \n",
        "    return 0\n",
        "  else:\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhZelP6nJ1Y9"
      },
      "outputs": [],
      "source": [
        "Y_preds2 = [convert_text_to_label(t) for t in preds_text2]\n",
        "Y_preds2 = np.array(Y_preds2)\n",
        "Y_test   = np.array(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az_7lvp-KWjD"
      },
      "outputs": [],
      "source": [
        "Y_test_filtered2  = Y_test[(Y_preds2==1) | (Y_preds2==-1)]\n",
        "Y_preds_filtered2 = Y_preds2[(Y_preds2==1) | (Y_preds2==-1)].astype(int)\n",
        "Y_preds_filtered2[Y_preds_filtered2==-1]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRhouy2rNSGv"
      },
      "outputs": [],
      "source": [
        "evaluate(Y_test_filtered2,Y_preds_filtered2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
